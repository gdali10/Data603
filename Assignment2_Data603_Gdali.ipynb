{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\dalig\\anaconda3\\anacondafolder\\lib\\site-packages (3.0.1)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0; python_version < \"3.10\" in c:\\users\\dalig\\anaconda3\\anacondafolder\\lib\\site-packages (from PyPDF2) (4.12.2)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages extracted and saved to file1.txt and file2.txt\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_pages(pdf_file, start_page, num_pages):   #Birthday: 11/09/1995\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(start_page - 1, start_page - 1 + num_pages):\n",
    "            text += reader.pages[page_num].extract_text()\n",
    "        return text\n",
    "\n",
    "book_file = r'C:\\Users\\dalig\\OneDrive\\Desktop\\UMBC Masters in Data Science\\Data 603\\Harry_Potter_(www.ztcprep.com).pdf'\n",
    "birth_date_page = 9\n",
    "birth_year_page = 195\n",
    "\n",
    "text1 = extract_pages(book_file, birth_date_page, 10)\n",
    "with open('file1.txt', 'w', encoding='utf-8') as f1:\n",
    "    f1.write(text1)\n",
    "\n",
    "text2 = extract_pages(book_file, birth_year_page, 10)\n",
    "with open('file2.txt', 'w', encoding='utf-8') as f2:\n",
    "    f2.write(text2)\n",
    "\n",
    "print(\"Pages extracted and saved to file1.txt and file2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts in file1.txt:\n",
      "p: 6\n",
      "a: 41\n",
      "g: 6\n",
      "e: 7\n",
      "4: 1\n",
      "harry: 10\n",
      "potter: 9\n",
      "and: 43\n",
      "the: 84\n",
      "philosophers: 6\n",
      "stone: 6\n",
      "j: 6\n",
      "k: 6\n",
      "rowling: 6\n",
      "calls: 1\n",
      "shouted: 1\n",
      "bit: 1\n",
      "more: 2\n",
      "he: 78\n",
      "was: 38\n",
      "in: 22\n",
      "very: 6\n",
      "good: 2\n",
      "mood: 2\n",
      "until: 4\n",
      "lunchtime: 1\n",
      "when: 6\n",
      "thought: 7\n",
      "d: 10\n",
      "stretch: 1\n",
      "his: 29\n",
      "legs: 1\n",
      "walk: 1\n",
      "across: 2\n",
      "road: 2\n",
      "to: 36\n",
      "buy: 1\n",
      "himself: 4\n",
      "bun: 1\n",
      "from: 4\n",
      "bakery: 1\n",
      "for: 9\n",
      "gotten: 1\n",
      "all: 10\n",
      "about: 6\n",
      "people: 6\n",
      "cloaks: 3\n",
      "passed: 2\n",
      "group: 1\n",
      "of: 28\n",
      "them: 7\n",
      "next: 5\n",
      "baker: 1\n",
      "s: 11\n",
      "eyed: 2\n",
      "angrily: 1\n",
      "as: 17\n",
      "didn: 12\n",
      "t: 27\n",
      "know: 4\n",
      "why: 3\n",
      "but: 8\n",
      "they: 7\n",
      "made: 2\n",
      "him: 9\n",
      "uneasy: 2\n",
      "this: 6\n",
      "bunch: 1\n",
      "were: 10\n",
      "whispering: 1\n",
      "excitedly: 1\n",
      "too: 1\n",
      "couldn: 3\n",
      "see: 3\n",
      "single: 1\n",
      "collecting: 1\n",
      "tin: 1\n",
      "it: 32\n",
      "on: 16\n",
      "way: 1\n",
      "back: 5\n",
      "past: 1\n",
      "clutching: 1\n",
      "lar: 1\n",
      "ge: 1\n",
      "doughnut: 1\n",
      "bag: 1\n",
      "that: 20\n",
      "caught: 1\n",
      "few: 2\n",
      "words: 1\n",
      "what: 5\n",
      "saying: 1\n",
      "potters: 5\n",
      "right: 1\n",
      "i: 8\n",
      "heard: 3\n",
      "yes: 2\n",
      "their: 5\n",
      "son: 3\n",
      "mr: 14\n",
      "dursley: 25\n",
      "stopped: 1\n",
      "dead: 1\n",
      "fear: 1\n",
      "flooded: 1\n",
      "looked: 4\n",
      "at: 12\n",
      "whisperers: 1\n",
      "if: 7\n",
      "wanted: 1\n",
      "say: 3\n",
      "something: 5\n",
      "better: 1\n",
      "dashed: 1\n",
      "hurried: 2\n",
      "up: 4\n",
      "www: 10\n",
      "ztcprep: 10\n",
      "com: 10\n",
      "fice: 1\n",
      "snapped: 2\n",
      "secretary: 1\n",
      "not: 4\n",
      "disturb: 1\n",
      "seized: 1\n",
      "telephone: 1\n",
      "had: 17\n",
      "almost: 3\n",
      "finished: 1\n",
      "dialing: 1\n",
      "home: 2\n",
      "number: 2\n",
      "changed: 2\n",
      "mind: 2\n",
      "put: 4\n",
      "receiver: 1\n",
      "down: 5\n",
      "stroked: 1\n",
      "mustache: 1\n",
      "thinking: 1\n",
      "no: 6\n",
      "being: 3\n",
      "stupid: 1\n",
      "wasn: 2\n",
      "such: 1\n",
      "an: 2\n",
      "unusual: 1\n",
      "name: 6\n",
      "sure: 3\n",
      "there: 6\n",
      "lots: 1\n",
      "called: 4\n",
      "who: 2\n",
      "come: 2\n",
      "think: 2\n",
      "even: 5\n",
      "nephew: 1\n",
      "never: 2\n",
      "seen: 3\n",
      "boy: 1\n",
      "might: 3\n",
      "have: 15\n",
      "been: 13\n",
      "harvey: 1\n",
      "or: 1\n",
      "harold: 1\n",
      "point: 1\n",
      "worrying: 1\n",
      "mrs: 12\n",
      "she: 4\n",
      "always: 1\n",
      "got: 3\n",
      "so: 6\n",
      "upset: 3\n",
      "any: 2\n",
      "mention: 2\n",
      "her: 7\n",
      "sister: 4\n",
      "blame: 1\n",
      "like: 3\n",
      "same: 3\n",
      "those: 1\n",
      "5: 1\n",
      "found: 2\n",
      "lot: 2\n",
      "harder: 1\n",
      "concentrate: 1\n",
      "drills: 1\n",
      "afternoon: 1\n",
      "left: 2\n",
      "building: 1\n",
      "five: 1\n",
      "o: 1\n",
      "clock: 1\n",
      "still: 5\n",
      "worried: 1\n",
      "walked: 2\n",
      "straight: 1\n",
      "into: 11\n",
      "someone: 1\n",
      "just: 5\n",
      "outside: 2\n",
      "door: 3\n",
      "sorry: 2\n",
      "grunted: 1\n",
      "tiny: 2\n",
      "old: 3\n",
      "man: 6\n",
      "stumbled: 1\n",
      "fell: 3\n",
      "seconds: 1\n",
      "before: 4\n",
      "realized: 1\n",
      "wearing: 2\n",
      "violet: 1\n",
      "cloak: 4\n",
      "seem: 3\n",
      "knocked: 1\n",
      "ground: 3\n",
      "contrary: 1\n",
      "face: 1\n",
      "split: 1\n",
      "wide: 1\n",
      "smile: 1\n",
      "said: 7\n",
      "squeaky: 1\n",
      "voice: 1\n",
      "passersby: 1\n",
      "stare: 1\n",
      "don: 2\n",
      "be: 7\n",
      "my: 1\n",
      "dear: 2\n",
      "sir: 1\n",
      "nothing: 2\n",
      "could: 5\n",
      "me: 3\n",
      "today: 4\n",
      "rejoice: 1\n",
      "y: 3\n",
      "ou: 1\n",
      "has: 1\n",
      "gone: 1\n",
      "last: 3\n",
      "muggles: 1\n",
      "yourself: 1\n",
      "should: 2\n",
      "celebrating: 2\n",
      "happy: 2\n",
      "day: 2\n",
      "hugged: 2\n",
      "around: 2\n",
      "middle: 1\n",
      "f: 4\n",
      "stood: 1\n",
      "rooted: 1\n",
      "spot: 1\n",
      "by: 3\n",
      "complete: 1\n",
      "stranger: 1\n",
      "also: 1\n",
      "muggle: 1\n",
      "whatever: 1\n",
      "rattled: 1\n",
      "car: 2\n",
      "set: 2\n",
      "hoping: 1\n",
      "imagining: 2\n",
      "things: 2\n",
      "which: 4\n",
      "hoped: 1\n",
      "because: 2\n",
      "approve: 1\n",
      "imagination: 1\n",
      "pulled: 1\n",
      "driveway: 1\n",
      "four: 1\n",
      "first: 1\n",
      "thing: 1\n",
      "saw: 1\n",
      "improve: 1\n",
      "tabby: 1\n",
      "cat: 11\n",
      "spotted: 1\n",
      "morning: 1\n",
      "now: 4\n",
      "sitting: 2\n",
      "garden: 2\n",
      "wall: 2\n",
      "one: 1\n",
      "markings: 1\n",
      "its: 3\n",
      "eyes: 5\n",
      "shoo: 1\n",
      "loudly: 1\n",
      "move: 1\n",
      "gave: 1\n",
      "stern: 1\n",
      "look: 1\n",
      "w: 5\n",
      "normal: 2\n",
      "behavior: 1\n",
      "wondered: 2\n",
      "rying: 1\n",
      "pull: 1\n",
      "together: 1\n",
      "let: 1\n",
      "6: 1\n",
      "house: 1\n",
      "determined: 1\n",
      "anything: 4\n",
      "wife: 1\n",
      "nice: 1\n",
      "told: 1\n",
      "over: 6\n",
      "dinner: 1\n",
      "problems: 1\n",
      "with: 5\n",
      "daughter: 1\n",
      "how: 3\n",
      "dudley: 3\n",
      "learned: 1\n",
      "new: 1\n",
      "word: 2\n",
      "tried: 1\n",
      "act: 1\n",
      "normally: 3\n",
      "bed: 3\n",
      "went: 3\n",
      "living: 2\n",
      "room: 2\n",
      "time: 1\n",
      "catch: 1\n",
      "report: 1\n",
      "evening: 1\n",
      "news: 2\n",
      "finally: 1\n",
      "bird: 1\n",
      "watchers: 1\n",
      "everywhere: 1\n",
      "reported: 1\n",
      "nation: 1\n",
      "owls: 8\n",
      "behaving: 1\n",
      "unusually: 1\n",
      "although: 1\n",
      "hunt: 1\n",
      "night: 3\n",
      "are: 2\n",
      "hardly: 1\n",
      "ever: 2\n",
      "daylight: 2\n",
      "hundreds: 1\n",
      "sightings: 1\n",
      "these: 1\n",
      "birds: 1\n",
      "flying: 2\n",
      "every: 1\n",
      "direction: 1\n",
      "since: 1\n",
      "sunrise: 1\n",
      "experts: 1\n",
      "unable: 1\n",
      "explain: 1\n",
      "suddenly: 3\n",
      "sleeping: 1\n",
      "pattern: 1\n",
      "newscaster: 1\n",
      "allowed: 1\n",
      "grin: 1\n",
      "most: 1\n",
      "mysterious: 2\n",
      "jim: 2\n",
      "mcguf: 1\n",
      "fin: 1\n",
      "weather: 1\n",
      "going: 2\n",
      "showers: 1\n",
      "tonight: 2\n",
      "ell: 2\n",
      "ed: 1\n",
      "weatherman: 1\n",
      "only: 2\n",
      "acting: 1\n",
      "oddly: 1\n",
      "v: 1\n",
      "iewers: 1\n",
      "far: 2\n",
      "apart: 1\n",
      "kent: 1\n",
      "orkshire: 1\n",
      "dundee: 1\n",
      "phoning: 1\n",
      "tell: 2\n",
      "instead: 2\n",
      "rain: 1\n",
      "promised: 1\n",
      "yesterday: 1\n",
      "ve: 1\n",
      "downpour: 1\n",
      "shooting: 3\n",
      "stars: 3\n",
      "perhaps: 1\n",
      "bonfire: 1\n",
      "early: 1\n",
      "week: 1\n",
      "folks: 1\n",
      "can: 1\n",
      "promise: 1\n",
      "wet: 1\n",
      "sat: 1\n",
      "frozen: 1\n",
      "armchair: 1\n",
      "britain: 1\n",
      "place: 1\n",
      "whisper: 2\n",
      "7: 1\n",
      "came: 1\n",
      "carrying: 1\n",
      "two: 3\n",
      "cups: 1\n",
      "tea: 2\n",
      "cleared: 1\n",
      "throat: 1\n",
      "nervously: 1\n",
      "er: 1\n",
      "petunia: 3\n",
      "you: 5\n",
      "haven: 1\n",
      "your: 1\n",
      "lately: 1\n",
      "expected: 1\n",
      "shocked: 1\n",
      "angry: 1\n",
      "after: 1\n",
      "pretended: 1\n",
      "sharply: 1\n",
      "funny: 2\n",
      "stuf: 1\n",
      "mumbled: 1\n",
      "looking: 3\n",
      "town: 1\n",
      "maybe: 1\n",
      "do: 2\n",
      "crowd: 1\n",
      "sipped: 1\n",
      "through: 1\n",
      "pursed: 1\n",
      "lips: 1\n",
      "whether: 1\n",
      "dared: 1\n",
      "decided: 1\n",
      "dare: 1\n",
      "casually: 1\n",
      "age: 1\n",
      "wouldn: 2\n",
      "suppose: 1\n",
      "stif: 1\n",
      "fly: 1\n",
      "again: 2\n",
      "howard: 1\n",
      "isn: 1\n",
      "nasty: 1\n",
      "common: 1\n",
      "ask: 1\n",
      "oh: 1\n",
      "heart: 1\n",
      "sinking: 1\n",
      "horribly: 1\n",
      "es: 1\n",
      "quite: 1\n",
      "agree: 1\n",
      "another: 1\n",
      "subject: 1\n",
      "upstairs: 1\n",
      "while: 1\n",
      "bathroom: 1\n",
      "crept: 1\n",
      "bedroom: 1\n",
      "window: 2\n",
      "8: 1\n",
      "peered: 1\n",
      "front: 1\n",
      "staring: 2\n",
      "privet: 3\n",
      "drive: 3\n",
      "though: 2\n",
      "waiting: 1\n",
      "did: 2\n",
      "out: 4\n",
      "related: 1\n",
      "pair: 1\n",
      "well: 2\n",
      "bear: 1\n",
      "dursleys: 1\n",
      "asleep: 2\n",
      "quickly: 1\n",
      "lay: 1\n",
      "awake: 1\n",
      "turning: 1\n",
      "comforting: 1\n",
      "wer: 1\n",
      "involved: 1\n",
      "reason: 2\n",
      "near: 1\n",
      "knew: 1\n",
      "kind: 1\n",
      "get: 1\n",
      "mixed: 1\n",
      "yawned: 1\n",
      "turned: 1\n",
      "af: 1\n",
      "fect: 1\n",
      "wrong: 1\n",
      "drifting: 1\n",
      "sleep: 1\n",
      "showing: 1\n",
      "sign: 1\n",
      "sleepiness: 1\n",
      "statue: 1\n",
      "fixed: 1\n",
      "unblinkingly: 1\n",
      "corner: 2\n",
      "much: 1\n",
      "quiver: 1\n",
      "slammed: 1\n",
      "street: 5\n",
      "nor: 1\n",
      "swooped: 1\n",
      "overhead: 1\n",
      "fact: 1\n",
      "nearly: 1\n",
      "midnight: 1\n",
      "moved: 1\n",
      "appeared: 2\n",
      "watching: 2\n",
      "silently: 1\n",
      "popped: 1\n",
      "tail: 1\n",
      "twitched: 1\n",
      "narrowed: 1\n",
      "tall: 1\n",
      "thin: 1\n",
      "judging: 1\n",
      "silver: 2\n",
      "hair: 1\n",
      "beard: 1\n",
      "both: 1\n",
      "long: 3\n",
      "9: 1\n",
      "enough: 1\n",
      "tuck: 1\n",
      "belt: 1\n",
      "robes: 1\n",
      "purple: 1\n",
      "swept: 1\n",
      "high: 1\n",
      "heeled: 1\n",
      "buckled: 1\n",
      "boots: 2\n",
      "blue: 1\n",
      "light: 1\n",
      "bright: 1\n",
      "sparkling: 1\n",
      "behind: 1\n",
      "half: 1\n",
      "moon: 1\n",
      "spectacles: 1\n",
      "nose: 1\n",
      "crooked: 1\n",
      "broken: 1\n",
      "least: 1\n",
      "twice: 1\n",
      "albus: 2\n",
      "dumbledore: 3\n",
      "realize: 2\n",
      "arrived: 1\n",
      "where: 1\n",
      "everything: 1\n",
      "unwelcome: 1\n",
      "busy: 1\n",
      "rummaging: 1\n",
      "watched: 1\n",
      "other: 1\n",
      "end: 1\n",
      "some: 1\n",
      "sight: 1\n",
      "seemed: 2\n",
      "amuse: 1\n",
      "chuckled: 1\n",
      "muttered: 1\n",
      "known: 1\n",
      "inside: 2\n",
      "pocket: 1\n",
      "cigarette: 1\n",
      "lighter: 1\n",
      "flicked: 1\n",
      "open: 1\n",
      "held: 1\n",
      "air: 1\n",
      "clicked: 3\n",
      "nearest: 1\n",
      "lamp: 2\n",
      "little: 1\n",
      "pop: 1\n",
      "flickered: 1\n",
      "darkness: 1\n",
      "welve: 1\n",
      "times: 1\n",
      "outer: 2\n",
      "lights: 1\n",
      "whole: 1\n",
      "pinpricks: 1\n",
      "distance: 1\n",
      "anyone: 1\n",
      "beady: 1\n",
      "able: 1\n",
      "happening: 1\n",
      "pavement: 1\n",
      "slipped: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def mapper(text):\n",
    "    word_count = defaultdict(int)\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    for word in words:\n",
    "        word_count[word] += 1\n",
    "    return word_count\n",
    "\n",
    "def reducer(mapped_data):\n",
    "    final_counts = defaultdict(int)\n",
    "    for word, count in mapped_data.items():\n",
    "        final_counts[word] += count\n",
    "    return final_counts\n",
    "\n",
    "with open('file1.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "mapped_data = mapper(text)\n",
    "final_word_count = reducer(mapped_data)\n",
    "\n",
    "print(\"Word counts in file1.txt:\")\n",
    "for word, count in final_word_count.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-English word counts in file2.txt:\n",
      "hogwarts: 4\n",
      "ou: 6\n",
      "gryf: 4\n",
      "findor: 3\n",
      "huf: 5\n",
      "flepuf: 5\n",
      "ravenclaw: 3\n",
      "slytherin: 4\n",
      "www: 10\n",
      "ztcprep: 10\n",
      "com: 10\n",
      "neville: 1\n",
      "ron: 5\n",
      "mcgonagall: 7\n",
      "128: 1\n",
      "rowling: 7\n",
      "fred: 2\n",
      "didn: 3\n",
      "hadn: 1\n",
      "hermione: 2\n",
      "dursleys: 1\n",
      "ar: 1\n",
      "guing: 1\n",
      "129: 1\n",
      "ruf: 1\n",
      "130: 1\n",
      "wouldn: 1\n",
      "pr: 1\n",
      "etty: 1\n",
      "ll: 3\n",
      "131: 1\n",
      "findors: 1\n",
      "fs: 1\n",
      "ve: 2\n",
      "132: 1\n",
      "abbott: 1\n",
      "hannah: 3\n",
      "133: 1\n",
      "hufflepuff: 3\n",
      "susan: 2\n",
      "erry: 2\n",
      "ra: 1\n",
      "vencla: 1\n",
      "ravenclaws: 1\n",
      "brocklehurst: 1\n",
      "mandy: 1\n",
      "bulstrode: 1\n",
      "millicent: 1\n",
      "dudley: 1\n",
      "134: 1\n",
      "fletchley: 1\n",
      "justin: 1\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "def is_non_english(word, spell):\n",
    "    return word not in spell\n",
    "\n",
    "def non_english_mapper(text, spell):\n",
    "    non_english_word_count = defaultdict(int)\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    for word in words:\n",
    "        if is_non_english(word, spell):\n",
    "            non_english_word_count[word] += 1\n",
    "    return non_english_word_count\n",
    "\n",
    "# Initializing the spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Reading file2.txt and using MapReduce\n",
    "with open('file2.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "non_english_mapped_data = non_english_mapper(text, spell)\n",
    "final_non_english_word_count = reducer(non_english_mapped_data)\n",
    "\n",
    "# Output\n",
    "print(\"\\nNon-English word counts in file2.txt:\")\n",
    "for word, count in final_non_english_word_count.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
